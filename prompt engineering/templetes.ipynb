{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_kb3erex7Cq"
      },
      "source": [
        "# Introducion to GenAI\n",
        "\n",
        "Mor Hananovitz (c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VmCkkGWkyZ-o"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mor.h/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables (you'll need to create a .env file with your OpenAI API key)\n",
        "load_dotenv()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\", max_tokens=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompt Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Name  Age  Score\n",
            "0   Person_1   56  39.52\n",
            "1   Person_2   69  92.67\n",
            "2   Person_3   46  72.73\n",
            "3   Person_4   32  32.65\n",
            "4   Person_5   60  57.04\n",
            "5   Person_6   25  52.08\n",
            "6   Person_7   78  96.12\n",
            "7   Person_8   38  84.45\n",
            "8   Person_9   56  74.73\n",
            "9  Person_10   75  53.97\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a random dataset with 3 columns\n",
        "np.random.seed(42)  # For reproducible results\n",
        "\n",
        "data = {\n",
        "    'Name': [f'Person_{i}' for i in range(1, 101)],\n",
        "    'Age': np.random.randint(18, 80, 100),\n",
        "    'Score': np.random.uniform(0, 100, 100).round(2)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Name    100 non-null    object \n",
            " 1   Age     100 non-null    int64  \n",
            " 2   Score   100 non-null    float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 2.5+ KB\n"
          ]
        }
      ],
      "source": [
        "info = df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats = df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "role = \"\"\"you are a data analyst\"\"\"\n",
        "\n",
        "style  = \"\"\"short and concise\"\"\"\n",
        "\n",
        "format = \"\"\"table for the results and short explenation for the data\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mPrompt: \n",
            "you are a you are a data analyst. Your task it to analize the dataframe:           Name  Age  Score\n",
            "0     Person_1   56  39.52\n",
            "1     Person_2   69  92.67\n",
            "2     Person_3   46  72.73\n",
            "3     Person_4   32  32.65\n",
            "4     Person_5   60  57.04\n",
            "..         ...  ...    ...\n",
            "95   Person_96   46  41.10\n",
            "96   Person_97   35   3.31\n",
            "97   Person_98   43  34.51\n",
            "98   Person_99   61  63.44\n",
            "99  Person_100   51  68.07\n",
            "\n",
            "[100 rows x 3 columns] and to average all numeric columns - for context use the following information: None,               Age      Score\n",
            "count  100.000000  100.00000\n",
            "mean    50.270000   48.57180\n",
            "std     19.176403   27.56722\n",
            "min     19.000000    0.05000\n",
            "25%     34.750000   26.41250\n",
            "50%     51.500000   46.59500\n",
            "75%     68.000000   69.49750\n",
            "max     79.000000   99.77000.\n",
            "\n",
            "output style: short and concise\n",
            "output format: table for the results and short explenation for the data\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[34mResponse: | Column | Average Value |\n",
            "|---------|--------------|\n",
            "| Age     | 50.27        |\n",
            "| Score   | 48.57        |\n",
            "\n",
            "The data consists of 100 individuals with ages ranging from 19 to 79, averaging around 50 years. Scores vary widely, averaging approximately 48.57, indicating diverse performance levels across the dataset.\u001b[0m \n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "you are a {role}. Your task it to analize the dataframe: {df} and to average all numeric columns - for context use the following information: {info}, {stats}.\n",
        "\n",
        "output style: {style}\n",
        "output format: {format}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = llm.invoke(prompt).content\n",
        "\n",
        "\n",
        "print(f\"\\033[31mPrompt: {prompt}\\033[0m\")\n",
        "print(\"\")\n",
        "print(f\"\\033[34mResponse: {response}\\033[0m \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mPrompt: You are a 17th century rationalist philosopher. \n",
            "    Your task is to answer the following question in the specified style and format.\n",
            "\n",
            "\n",
            "    Style: You have a very deep and complex knowledge of philosophy and you are able to explain it in a way that is easy to understand.\n",
            "\n",
            "    Format: You answer should be a rap song.\n",
            "\n",
            "\n",
            "    Question: what is the meaning of life?\u001b[0m\n",
            "\n",
            "\u001b[34mResponse: Yo, listen up, I’ma break it down deep,  \n",
            "The meaning of life, it ain’t just to sleep,  \n",
            "It’s that spark in the soul, that rational fire,  \n",
            "To seek truth and knowledge, to lift us higher.  \n",
            "  \n",
            "From Descartes’ mind, I think, therefore I am,  \n",
            "Our essence’s reason, that’s who I am,  \n",
            "We question, explore, through doubt we refine,  \n",
            "Finding the divine in the reasoned design.  \n",
            "  \n",
            "Life’s about the quest, the pursuit of the good,  \n",
            "Living with virtue, doing what we should,  \n",
            "Not just fleeting pleasures or superficial gains,  \n",
            "But eternal truths that lessen our pains.  \n",
            "  \n",
            "In measure and order, the cosmos align,  \n",
            "A divine reason, poetic and divine,  \n",
            "So grasp your mind, let logic be your guide,  \n",
            "That’s the true meaning—wisdom deep inside.  \n",
            "  \n",
            "So walk with purpose, with a rational mind,  \n",
            "In pursuit of truth, eternal we find,  \n",
            "That life’s most profound, in the soul’s own quest,  \n",
            "Is to reason, to love—be your very best.\u001b[0m \n"
          ]
        }
      ],
      "source": [
        "role = \"17th century rationalist philosopher\"\n",
        "style = \"You have a very deep and complex knowledge of philosophy and you are able to explain it in a way that is easy to understand.\"\n",
        "format_ = \"You answer should be a rap song.\"\n",
        "question = \"what is the meaning of life?\"\n",
        "\n",
        "prompt = (\n",
        "    f\"\"\"You are a {role}. \n",
        "    Your task is to answer the following question in the specified style and format.\\n\\n\n",
        "    Style: {style}\\n\n",
        "    Format: {format_}\\n\\n\n",
        "    Question: {question}\"\"\"\n",
        ")\n",
        "response = llm.invoke(prompt).content\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:\n",
            "\u001b[31mPrompt: \n",
            "You are a 17th century rationalist philosopher. \n",
            "    Your task is to answer the following question in the specified style and format.\n",
            "\n",
            "\n",
            "    Style: You have a very deep and complex knowledge of philosophy and you are able to explain it in a way that is easy to understand.\n",
            "\n",
            "    Format: You answer should be a rap song.\n",
            "\n",
            "\n",
            "    Question: what is the meaning of life?\u001b[0m\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\u001b[34mResponse:\n",
            " Yo, listen up, I’ma break it down deep,   The meaning of life, it ain’t just to\n",
            "sleep,   It’s that spark in the soul, that rational fire,   To seek truth and\n",
            "knowledge, to lift us higher.      From Descartes’ mind, I think, therefore I\n",
            "am,   Our essence’s reason, that’s who I am,   We question, explore, through\n",
            "doubt we refine,   Finding the divine in the reasoned design.      Life’s about\n",
            "the quest, the pursuit of the good,   Living with virtue, doing what we should,\n",
            "Not just fleeting pleasures or superficial gains,   But eternal truths that\n",
            "lessen our pains.      In measure and order, the cosmos align,   A divine\n",
            "reason, poetic and divine,   So grasp your mind, let logic be your guide,\n",
            "That’s the true meaning—wisdom deep inside.      So walk with purpose, with a\n",
            "rational mind,   In pursuit of truth, eternal we find,   That life’s most\n",
            "profound, in the soul’s own quest,   Is to reason, to love—be your very best.\u001b[0m \n"
          ]
        }
      ],
      "source": [
        "print(\"prompt:\")\n",
        "print(f\"\\033[31mPrompt: \\n{prompt}\\033[0m\")\n",
        "print(\"\")\n",
        "print(\"-\"*100)\n",
        "import textwrap\n",
        "wrapped_response = textwrap.fill(response, width=80)\n",
        "print(f\"\\033[34mResponse:\\n {wrapped_response}\\033[0m \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis + Shots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zero Shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "review = \"\"\"\n",
        "לא אכלתי. ראתי את מחירי הפיצות וניבהלתי. 80 שח לפיצה אישית זה מוגזם.\n",
        "תפריט יש רק דיגיטלי בסריקת קוד, קשישים ואוטיסטים רבים יתקשו להזמין שם.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Perform a sentiment analysis on the following restaurant review into 3 sentiment groups: positive, neutral, and negative.\n",
        "\n",
        "Review: {review}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = gpt4o_chat.invoke(prompt).content\n",
        "\n",
        "\n",
        "print(f\"\\033[31mPrompt: {prompt}\\033[0m\")\n",
        "print(\"\")\n",
        "print(f\"\\033[34mResponse: {response}\\033[0m \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Few Shots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Perform a sentiment analysis on the following restaurant review into 3 sentiment groups: positive, neutral, and negative.\n",
        "\n",
        "Review: {review}\n",
        "\n",
        "Examples:\n",
        "Review 1: \"הזמננו דרך וולט. לקח הרבה זמן. הפיצה היתה קרה כמו סוליה של מגף. הפסטות מוצפות בשמן, שמנות נורא, לא מורגש שום טעם חוץ משל שמן זול. בטוח לא הטעם של כמהין שהיה מובטח.\n",
        "פסטה מבושלת יותר מדי, לא al dente.\n",
        "אכזבה גדולה. מצטער שהתעצלתי ולא טגנתי במקום ההזמנה הזאת איזה שניצל או לא בישלתי פסטה נורמלית טעימה בעצמי.\n",
        "פעם ראשונה ואחרונה.\n",
        "לא מומלץ בשום אופן.\"\n",
        "Sentiment: negative\n",
        "\n",
        "Review 2: \" פיצה בינונית מאוד, נמכרת במחיר 80-90 שקל למגש כאילו זו פיצת שף,\n",
        "הבצק דחוס ובקשוי תפח, והגבינה עלובה (בטח איזשהי גבינה שקונים מגורדת)\n",
        "אם הייתה לי בחינת טעימה עיוורת, הייתי מנחש שמדובר בפיצה ב- 36שח למגש בתחנה מרכזית\"\n",
        "Sentiment: neutral\n",
        "\n",
        "Review 3: \"עדיין הפיצה הכי טובה בעיר. פיצה איכותית, עשירה, תפריט מדליק.\n",
        "ממליץ על פיצה אה-לה-רומנה או פפרוני.\n",
        "הבצק קריספי בטירוף ורואים שהושקעה מחשבה בהגשה. הישיבה ברחוב המלבן פינת כצנלסון נעימה וכיפית.\n",
        "\n",
        "תמיד נעים לחזור - תודה לכם צוות פאצה פיצה.\"\n",
        "Sentiment: positive\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = gpt4o_chat.invoke(prompt).content\n",
        "\n",
        "\n",
        "print(f\"\\033[31mPrompt: {prompt}\\033[0m\")\n",
        "print(\"\")\n",
        "print(f\"\\033[34mResponse: {response}\\033[0m \")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
